{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c0f51b8",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245557b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf847386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcoded to get header and likelihood header names and index\n",
    "headertotal = list(pd.read_csv('',header = 0).columns.values) #add file\n",
    "likelihood_columnindex = [index for index, string in enumerate(headertotal) if 'likelihood' in string]\n",
    "likelihood_columnnames = [headertotal[x] for x in likelihood_columnindex]\n",
    "print(likelihood_columnnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testtrial = pd.read_csv('',header = 0) #add file\n",
    "list_trial = []\n",
    "for index, row in df_testtrial.iterrows():\n",
    "    list_trial.append(row.loc['nose.2likelihood'])           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa8378",
   "metadata": {},
   "source": [
    "First, loop through all the downsampled csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23aac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for saving amounts\n",
    "nose_dict = dict()\n",
    "earl_dict = dict()\n",
    "earr_dict = dict()\n",
    "shoulderl_dict = dict()\n",
    "shoulderr_dict = dict()\n",
    "tail_dict = dict()\n",
    "\n",
    "# loop through video paths\n",
    "for path in list(input_dir.glob(\"*.csv*\")):\n",
    "    \n",
    "    #load data\n",
    "    df_load = pd.read_csv(path,header=0)\n",
    "    \n",
    "    # loop through data\n",
    "    under = np.zeros(6)\n",
    "    total = len(df_load)\n",
    "    \n",
    "    for index, row in df_load.iterrows():\n",
    "        for i in likelihood_columnnames:\n",
    "            if row.loc[i] <= 0.50:\n",
    "                under[likelihood_columnnames.index(i)] += 1  \n",
    "    \n",
    "    nose_dict[path.stem] = (under[0]/total)*100\n",
    "    earl_dict[path.stem] = (under[1]/total)*100\n",
    "    earr_dict[path.stem] = (under[2]/total)*100\n",
    "    shoulderl_dict[path.stem] = (under[3]/total)*100\n",
    "    shoulderr_dict[path.stem] = (under[4]/total)*100\n",
    "    tail_dict[path.stem] = (under[5]/total)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8eddf",
   "metadata": {},
   "source": [
    "Show all values for the bodyparts over all videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nose = list(nose_dict.values())\n",
    "list_earl = list(earl_dict.values())\n",
    "list_earr = list(earr_dict.values())\n",
    "list_shoulderl = list(shoulderl_dict.values())\n",
    "list_shoulderr = list(shoulderr_dict.values())\n",
    "list_tail = list(tail_dict.values())\n",
    "\n",
    "bodyparts_forhist = [list_nose,list_earl,list_earr,list_shoulderl,list_shoulderr,list_tail]\n",
    "bodyparts = ['nose', 'left ear', 'right ear', 'left shoulder', 'right shoulder', 'tailbase']\n",
    "\n",
    "for i in range(len(bodyparts_forhist)):\n",
    "    plt.hist(bodyparts_forhist[i], bins=50, edgecolor='black', linewidth=1.2)\n",
    "    plt.title('Histogram of {} frames percentage under 0.5 likelihood after downsampling'.format(bodyparts[i]))\n",
    "    plt.xlabel('Percentage of frames under 0.50 likelihood')\n",
    "    plt.ylabel('Amount of videos')\n",
    "    plt.savefig('{}percentage_downsampled.png'.format(bodyparts[i])) #change file output\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa7b63",
   "metadata": {},
   "source": [
    "Get smallest and largest percentage + videoname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc62eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smallest index nose:')\n",
    "print(nose_dict[min(nose_dict, key=nose_dict.get)], min(nose_dict, key=nose_dict.get))\n",
    "print('largest index nose:')\n",
    "print(nose_dict[max(nose_dict, key=nose_dict.get)], max(nose_dict, key=nose_dict.get))\n",
    "\n",
    "print('smallest index earl:')\n",
    "print(earl_dict[min(earl_dict, key=earl_dict.get)], min(earl_dict, key=earl_dict.get))\n",
    "print('largest index earl:')\n",
    "print(earl_dict[max(earl_dict, key=earl_dict.get)], max(earl_dict, key=earl_dict.get))\n",
    "\n",
    "print('smallest index earr:')\n",
    "print(earr_dict[min(earr_dict, key=earr_dict.get)], min(earr_dict, key=earr_dict.get))\n",
    "print('largest index earr:')\n",
    "print(earr_dict[max(earr_dict, key=earr_dict.get)], max(earr_dict, key=earr_dict.get))\n",
    "\n",
    "print('smallest index shoulderl:')\n",
    "print(shoulderl_dict[min(shoulderl_dict, key=shoulderl_dict.get)], min(shoulderl_dict, key=shoulderl_dict.get))\n",
    "print('largest index shoulderl:')\n",
    "print(shoulderl_dict[max(shoulderl_dict, key=shoulderl_dict.get)], max(shoulderl_dict, key=shoulderl_dict.get))\n",
    "\n",
    "print('smallest index shoulderr:')\n",
    "print(shoulderr_dict[min(shoulderr_dict, key=shoulderr_dict.get)], min(shoulderr_dict, key=shoulderr_dict.get))\n",
    "print('largest index shoulderr:')\n",
    "print(shoulderr_dict[max(shoulderr_dict, key=shoulderr_dict.get)], max(shoulderr_dict, key=shoulderr_dict.get))\n",
    "\n",
    "print('smallest index tail:')\n",
    "print(tail_dict[min(tail_dict, key=tail_dict.get)], min(tail_dict, key=tail_dict.get))\n",
    "print('largest index tail:')\n",
    "print(tail_dict[max(tail_dict, key=tail_dict.get)], max(tail_dict, key=tail_dict.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e464b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nose = statistics.mean(list(nose_dict.values())) \n",
    "mean_earl = statistics.mean(list(earl_dict.values())) \n",
    "mean_earr = statistics.mean(list(earr_dict.values())) \n",
    "mean_shoulderl = statistics.mean(list(shoulderl_dict.values())) \n",
    "mean_shoulderr = statistics.mean(list(shoulderr_dict.values()))  \n",
    "mean_tail = statistics.mean(list(tail_dict.values())) \n",
    "meanlist = [mean_nose,mean_earl,mean_earr,mean_shoulderl,mean_shoulderr,mean_tail]\n",
    "for i in range(len(meanlist)):\n",
    "    print(('mean percentage of {} over downsampled videos'.format(bodyparts[i])))\n",
    "    print(meanlist[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
