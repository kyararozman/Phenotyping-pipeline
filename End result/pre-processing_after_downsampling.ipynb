{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd3edd6",
   "metadata": {},
   "source": [
    "Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e63b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33aefa",
   "metadata": {},
   "source": [
    "set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de8034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.90 #for all points being above threshold likelihood\n",
    "# there are also filepaths that can be changed at the end of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290c53f",
   "metadata": {},
   "source": [
    "set directory path and make folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify starting directory as the one we are working in now with this Jupyter file\n",
    "input_dir = Path.cwd()\n",
    "\n",
    "# make folder for processed files\n",
    "os.makedirs(\"processed_data_seperate_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e37fe1",
   "metadata": {},
   "source": [
    "Read in all the downsampled data files and put in big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92bc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create big dataframe\n",
    "df_big = pd.DataFrame() \n",
    "\n",
    "# loop through video paths\n",
    "for path in list(input_dir.rglob(\"*.csv*\")):\n",
    "    \n",
    "    #load data\n",
    "    df_load = pd.read_csv(path,header=0)\n",
    "    \n",
    "    # append data to big dataframe\n",
    "    df_big = pd.concat([df_big, df_load], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b3eef",
   "metadata": {},
   "source": [
    "Extract column names and get likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fabbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select datacolumns that contain likelihood\n",
    "headertotal = list(df_big.columns.values)\n",
    "likelihood_columnindex = [index for index, string in enumerate(headertotal) if 'likelihood' in string]\n",
    "likelihood_columnnames = [headertotal[x] for x in likelihood_columnindex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1cbe4b",
   "metadata": {},
   "source": [
    "Slicing the beginning of the video through 20 consistent frames above 0.90 likelihood for all bodyparts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3961e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for retreiving index of when data was cut for analysis purposes later\n",
    "dict_cutbeginning = {}\n",
    "\n",
    "# get index of where data is consistently above threshold for 1 second so 20 frames.\n",
    "# Dataframe for begin slicing\n",
    "df_begincut = pd.DataFrame()\n",
    "    \n",
    "# loop through df_big per video \n",
    "for vid in df_big['videoname'].unique():\n",
    "    \n",
    "    df_interim = df_big.loc[df_big[\"videoname\"] == vid]\n",
    "    df_interim = df_interim[likelihood_columnnames]\n",
    "\n",
    "    def check_consecutive(row):\n",
    "        return(all(row>thres))\n",
    "    \n",
    "    booll = df_interim.apply(check_consecutive,axis=1)  \n",
    "    \n",
    "    consec_count = 0\n",
    "    end = None\n",
    "\n",
    "    for i, value in enumerate(booll):\n",
    "        if value:\n",
    "            consec_count += 1\n",
    "            if consec_count == 20:\n",
    "                end = i # index of the last value of the consecutive frames\n",
    "                break\n",
    "        else:\n",
    "            consec_count = 0\n",
    "            end = None\n",
    "    \n",
    "    #append index per video to dict\n",
    "    dict_cutbeginning[vid]= end\n",
    "    \n",
    "    #slicing the beginning using end_index \n",
    "    df_filter = df_big[df_big['videoname']==vid]\n",
    "    df_begincut = df_begincut.append(df_filter.iloc[end + 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63074e3d",
   "metadata": {},
   "source": [
    "Print smallest and largest index to show the difference of data we cut, although I checked this and it is just until the researcher put the rat in, so it is empty arena data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('smallest index:')\n",
    "print(dict_cutbeginning[min(dict_cutbeginning, key=dict_cutbeginning.get)], min(dict_cutbeginning, key=dict_cutbeginning.get))\n",
    "print('largest index:')\n",
    "print(dict_cutbeginning[max(dict_cutbeginning, key=dict_cutbeginning.get)], max(dict_cutbeginning, key=dict_cutbeginning.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b609c6dc",
   "metadata": {},
   "source": [
    "Slicing of the end of the video. Looping from the end 20 frames above 0.90 likelihood, cut from the 'beginning' of the 20 frames so we don't lose data. It is just a security in case the rat's got taken out from the arena while the camera was still on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4465d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for second slicing\n",
    "df_secondcut = pd.DataFrame()\n",
    "    \n",
    "# loop through df_begincut per video \n",
    "for vid in df_begincut['videoname'].unique():\n",
    "    \n",
    "    df_interim2 = df_begincut.loc[df_begincut[\"videoname\"] == vid]\n",
    "    df_interim2 = df_interim2[likelihood_columnnames]\n",
    "    \n",
    "    # perform boolean function defined above\n",
    "    booll2 = df_interim2.apply(check_consecutive,axis=1) \n",
    "    \n",
    "    consec_count2 = 0\n",
    "    end2 = None\n",
    "\n",
    "    for i, value in reversed(list(enumerate(booll2))):\n",
    "        if value:\n",
    "            if consec_count2 == 0:\n",
    "                end2 = i # index of the 'last value'\n",
    "            consec_count2 += 1\n",
    "            if consec_count2 == 20:\n",
    "                break\n",
    "        else:\n",
    "            consec2_count = 0\n",
    "            end2 = None\n",
    "    \n",
    "    #slicing the end using end_index \n",
    "    df_filter2 = df_begincut[df_begincut['videoname']==vid]\n",
    "    df_secondcut = df_secondcut.append(df_filter2.iloc[:end2+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c0178",
   "metadata": {},
   "source": [
    "Select the smallest video to use as general video size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabf3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting smallest 'dataframe'\n",
    "smallest = df_secondcut.groupby('videoname').size().min()\n",
    "print(smallest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd907566",
   "metadata": {},
   "source": [
    "Slice all the videos based on the smallest dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38dbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing the end using the smallest dataframe\n",
    "df_endcut = pd.DataFrame()\n",
    "for vid in df_secondcut['videoname'].unique():\n",
    "    df_filter3 = df_secondcut[df_secondcut['videoname']==vid]\n",
    "    df_endcut = df_endcut.append(df_filter3.iloc[:smallest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there is data\n",
    "df_endcut.head()\n",
    "\n",
    "# check how many videos\n",
    "print(len(df_endcut['videoname'].unique()))\n",
    "\n",
    "# check that all videos are the same length\n",
    "print(df_endcut.groupby('videoname').size().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b0ca9",
   "metadata": {},
   "source": [
    "Export all seperate videos after being processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all frames based on groupby\n",
    "# file paths for exporting data\n",
    "filepath = \"\" #edit\n",
    "\n",
    "# export as big dataframe\n",
    "df_endcut.to_csv(filepath+\"sliced_bigdf.csv\",index=False)\n",
    "\n",
    "# export for single videos\n",
    "for vid in df_endcut['videoname'].unique():\n",
    "    filename = vid + '.csv'\n",
    "    df_export_sliced = df_endcut[df_endcut['videoname']==vid]\n",
    "    df_export_sliced.to_csv(filepath+filename,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
